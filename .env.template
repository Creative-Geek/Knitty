# Fast LLM Configuration (for keyword extraction)
# Any LLM larger than 14B is recommended
FAST_LLM_API_KEY=""
FAST_LLM_API_BASE="https://api.groq.com/openai/v1"
FAST_LLM_MODEL_NAME="openai/gpt-oss-120b"

# Context LLM Configuration (for large document processing)
# Gemini 2.5 Flash is recommended
CONTEXT_LLM_API_KEY=""
CONTEXT_LLM_API_BASE="https://generativelanguage.googleapis.com/v1beta/openai/"
CONTEXT_LLM_MODEL_NAME="gemini-2.5-flash"

# Embed LLM Configuration (for generating embeddings)
# Local Embedding using embeddinggemma is recommended
EMBED_LLM_API_KEY="ollama"
EMBED_LLM_API_BASE="http://localhost:11434"
EMBED_LLM_MODEL_NAME="embeddinggemma:latest"


# Smart LLM (for CV generation)
# Gemini 2.5 Pro is recommended
SMART_LLM_API_KEY=""
SMART_LLM_API_BASE="https://generativelanguage.googleapis.com/v1beta/openai"
SMART_LLM_MODEL_NAME="gemini-2.5-pro"