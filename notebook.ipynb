{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b698bf3",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee87575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, json,sys\n",
    "\n",
    "# langsh*t (should find an alternative asap!)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document # required for splitting the text using lang****\n",
    "from langchain_core.prompts import ChatPromptTemplate # Could do without it\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.sync_api import sync_playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8fa535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.groq.com/openai/v1\n"
     ]
    }
   ],
   "source": [
    "# get ai provider api endpoints and keys from .env\n",
    "load_dotenv()\n",
    "print(os.getenv(\"FAST_LLM_API_BASE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af2482",
   "metadata": {},
   "source": [
    "## Get Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1124cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobPostingUrl=\"https://www.linkedin.com/jobs/view/4292529710\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6d2f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs/view/4292529710\n"
     ]
    }
   ],
   "source": [
    "cvPath=\"examples/cv.pdf\"\n",
    "jobPostingPath = \"examples/jobPostingText.txt\"\n",
    "additionalInfoPath = \"examples/additionalInfo.txt\"\n",
    "\n",
    "# check if jobPostingUrl is defined\n",
    "try:\n",
    "    print(jobPostingUrl)\n",
    "except:\n",
    "    jobPostingUrl=\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76de4e8",
   "metadata": {},
   "source": [
    "## Static inputs\n",
    "Prompts & Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab0c8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_config_file(filename):\n",
    "    \"\"\"Load configuration files from the config directory\"\"\"\n",
    "    config_path = os.path.join('config', filename)\n",
    "    with open(config_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "cvTemplate = load_config_file('cvTemplate.txt')\n",
    "cvKeywordsPrompt = load_config_file('cvKeywordsPrompt.txt')\n",
    "jobKeywordsPrompt = load_config_file('jobKeywordsPrompt.txt')\n",
    "jobRagPrompt = load_config_file('jobRagPrompt.txt')\n",
    "\n",
    "print(\"Everything loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00570a8d",
   "metadata": {},
   "source": [
    "## Process Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d45d9e",
   "metadata": {},
   "source": [
    "Handle CV and Additonal Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54509e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------\n",
      "CV Raw Text:\n",
      "------------\n",
      "Ahmed Taha\n",
      "Fresh Software Engineer\n",
      " ahmedtaha1234@gmail.com  +201557528856  Cairo, Egypt  creative-geek.tech  github.com/Creative-Geek\n",
      " linkedin.com/in/ahmed-taha-thecg  Exempted\n",
      "PROFILE\n",
      "Freshly graduated Software Engineer with hands-on experience in web development, AI integrations & Automation, and\n",
      "multimedia production. Skilled in React, Nodejs, Flask, and Python, aspires to create dynamic, user-friendly applications. Has\n",
      "delivered projects from web solutions to AI-driven tools‚Äîincluding an Arabic Handwriting E2E OCR system. Strong in UI/UX\n",
      "design and committed to crafting efficient, engaging digital experiences.\n",
      "PROJECTS\n",
      "Tasky,AI-Powered Todo List 04/2025 ‚Äì 05/2025\n",
      "Developed a fullstack todo list app with React, Node.js, and Prisma, focusing on user-friendly design and smooth\n",
      "animations.\n",
      "Deployed the client, server, and Postgres database, while enforcing security best practices.\n",
      "Integrated an AI that turns pasted coworker messages into tasks automatically.\n",
      "CG Blog,FOSS markdown dynamic site generator 01/2025 ‚Äì 06/2025\n",
      "Built a Head-only React-based blog and portfolio with Shadcn for use with any markdown files.\n",
      "Implemented custom dynamic RTL language support for Arabic, and SSR for SEO optimizations.\n",
      "Prioritized beginner-friendly UX with a minimalist design and plug-and-play configuration.\n",
      "Digital- D Ã£ aÃÑd \u0000Ôª™\u0000Ôª§\u0000\u0000ÿßÔªüÔ∫Æ\u0000- \u0000ÿµ,Graduation Project 03/2023 ‚Äì 07/2024\n",
      "Designed and implemented a React application for scanning, recognizing, and grading handwritten Arabic exams.\n",
      "Developed an OCR model with CNN and Bi-LSTM networks, achieving a 97% accuracy rate‚Äîan improvement from the\n",
      "previous 87%‚Äîusing a custom dataset of more than 100,000 samples.\n",
      "Built an image labeling app with user contribution tracking using React and Supabase.\n",
      "Developed an Agentic LLM to grade exams based on a model answer using Vertex AI Platform.\n",
      "The research was published at ‚ÄúAI for SDGs‚Äù Conference in 2024, as well as in ‚ÄúIJT‚Äù journal.\n",
      "The Platformer Test,Video Game Project 12/2022 ‚Äì 12/2022\n",
      "Developed a fully functional platformer video game with 3 levels using Godot Engine without prior knowledge in a\n",
      "single week.\n",
      "Time Estimator,Simple application to plan data transfers. 05/2021 ‚Äì 06/2021\n",
      "Created an app that estimates data transfer times based on speed, time, or size.\n",
      "Featuring a user friendly, intuitive, and OS-independent custom GUI using QT5.\n",
      "SKILLS\n",
      "Technical Skills\n",
      "‚Äî Programming & Frameworks: Python, C++, JavaScript, Typescript, React, React Native, Next.js, Vue, Flask, FastAPI,\n",
      "Django, Node.js, WordPress. | Generative AI: LLMs, Agent AIs, LangChain, Stable Diffusion, Flux, Vertex AI Platform |\n",
      "AI/ML: TensorFlow, Image Processing. | Cloud & Containerization: Google Cloud, Azure, Docker. | Tools & Technologies:\n",
      "GitHub, Git, Jira, Linux, Prisma, SQLite, PostgreSQL, MongoDB, Godot Engine, QT. | Multimedia & Design: Graphic Design,\n",
      "Video Editing, Motion Graphics, Adobe Creative Suite, UI/UX Design. | Technical Communication: Technical Writing,\n",
      "Content Creation.\n",
      "Soft Skills\n",
      "‚Äî Communication, Teamwork, Problem-Solving, Adaptability, Creativity, Time Management, Detail-Oriented.\n",
      "TECHNICAL EXPERIENCE\n",
      "Software Developer & IT Specialist,ELHODA MEP Contracting 09/2021 ‚Äì 09/2022 | Cairo, Egypt\n",
      "Implemented and managed an on-premises custom file server.\n",
      "Developed automation scripts that interact with Excel and Autocad to enhance team efficiency.\n",
      "Provided software and hardware technical support.\n",
      "Store Developer,CompuMall 06/2023 ‚Äì 09/2023 | Ismailia, Egypt\n",
      "Developed the company E-Commerce website using WordPress.\n",
      "Performed on-site computer repairs, and resolved complex technical issues for customers.\n",
      "Graphics Designer,Kunai Store 07/2024 ‚Äì 05/2025 | Saudi Arabia (Remote)\n",
      "Created visually engaging designs for websites, advertisements, and social media platforms, contributing to over\n",
      "600% sales.\n",
      "Tech Content Writer,E-CAMP 07/2024 ‚Äì 11/2024 | Cairo, Egypt\n",
      "Wrote articles simplifying technological concepts related to AI and software engineering.\n",
      "EDUCATION\n",
      "Faculty of Engineering, Suez Canal University, 09/2019 ‚Äì 07/2024 | Ismailia, Egypt\n",
      "Bachelor in Computer Engineering | GPA: B- | Graduation Project Grade: Excellent\n",
      "---------------\n",
      "Additional Info:\n",
      "---------------\n",
      "I'm freshly graduated\n",
      "I also have experience in IT and I'm pationate about fixing computers.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# read cv:\n",
    "loader = PyPDFLoader(cvPath)\n",
    "pages = []\n",
    "for page in loader.load():\n",
    "    pages.append(page)\n",
    "# join pages into a single string\n",
    "cvRawText = \"\\n\".join([page.page_content for page in pages])\n",
    "\n",
    "# read additional info\n",
    "with open(additionalInfoPath, 'r', encoding='utf-8') as file:\n",
    "    additionalInfo = file.read().strip()\n",
    "\n",
    "# combine cv and additional info\n",
    "if additionalInfo:\n",
    "    cvText = f\"\"\"\n",
    "------------\n",
    "CV Raw Text:\n",
    "------------\n",
    "{cvRawText}\n",
    "---------------\n",
    "Additional Info:\n",
    "---------------\n",
    "{additionalInfo}\n",
    "    \"\"\"\n",
    "else:\n",
    "    cvText = cvRawText\n",
    "print(cvText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ea30b",
   "metadata": {},
   "source": [
    "### Handle Job Posting\n",
    "\n",
    "Here we're gonna define a couple of functions to handle the job posting.\n",
    "\n",
    "if job posting is url -> fetch html -> clean it -> embed it -> rag it to get the job posting text\n",
    "\n",
    "if it's a text then we're done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f87b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a couple of functions for url job posting extraction (probably the longest part of this program)\n",
    "# This üëá was a pain to run inside the jupyter notebook on windows\n",
    "async def fetchUrl(jobPostingUrl):\n",
    "    if sys.platform == 'win32':\n",
    "        import asyncio\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "    def run_sync_playwright():\n",
    "        with sync_playwright() as p:\n",
    "            browser = p.chromium.launch(headless=True)\n",
    "            context = browser.new_context()\n",
    "            page = context.new_page()\n",
    "            page.goto(jobPostingUrl)\n",
    "\n",
    "            data = {\n",
    "                'url': page.url,\n",
    "                'title': page.title(),\n",
    "                'content': page.content(),\n",
    "            }\n",
    "\n",
    "            browser.close()\n",
    "            return data['content']\n",
    "    # run the code in a separate thread (because notebook)\n",
    "    content = await asyncio.to_thread(run_sync_playwright)\n",
    "    return content\n",
    "\n",
    "\n",
    "# removing anything but text from the html\n",
    "def cleanHTML(jobPostingHTML):\n",
    "    soup = BeautifulSoup(jobPostingHTML, \"html.parser\")\n",
    "    \n",
    "    # Remove script and style tags\n",
    "    for tag in soup([\"script\", \"style\"]):\n",
    "        tag.decompose() # weird naming but I'll alow it\n",
    "    \n",
    "    text = soup.get_text(separator=\"\\n\", strip=True) # get text ONLY! (separated by line)\n",
    "    return text\n",
    "\n",
    "# a function for generating embeddings\n",
    "def embed(text):\n",
    "    # Get ready for embedding\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=os.getenv(\"EMBED_LLM_MODEL_NAME\"),\n",
    "        api_key=os.getenv(\"EMBED_LLM_API_KEY\"),\n",
    "        base_url=os.getenv(\"EMBED_LLM_API_BASE\"),\n",
    "    )\n",
    "    \n",
    "    # Text splitter definition\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=2000, chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    documents = [Document(page_content=text)] # because lang****\n",
    "    \n",
    "    # Now split the text\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Created {len(chunks)} chunks.\")\n",
    "    \n",
    "    # Embed! Put in memory (see? we're not storing anything!)\n",
    "    print(\"Creating vector store with OpenAI embeddings...\")\n",
    "    vector_store = InMemoryVectorStore.from_documents(chunks, embeddings)\n",
    "    # ‚ö†Ô∏è‚ö†Ô∏è BIG TODO: embedding those in one request WILL FAIL with very large text (which is stupid because that's why we're doing RAG in the first place)\n",
    "    # Solution? batch processing, send multiple requests each with like 16-32 chunks or something\n",
    "    print(\"Vector store ready.\")\n",
    "    \n",
    "    return vector_store\n",
    "\n",
    "#RAAAAAAAAAAG!\n",
    "def doRAG(jobExtractedText):\n",
    "    \n",
    "    # Embed the job posting\n",
    "    vector_store = embed(jobExtractedText)\n",
    "    \n",
    "    # Retrieve\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3}) # could try more chunks but since beautiful soup already cleaned the text, it should be fine\n",
    "    query = \"job title responsibilities qualifications requirements description\" # TODO: git gud at prompt engineering\n",
    "    relevant_pieces = retriever.invoke(query)\n",
    "    \n",
    "    # Quick check in case it fails\n",
    "    if not relevant_pieces:\n",
    "        print(\"No relevant chunks found.\")\n",
    "        return None\n",
    "    combined_context = \"\\n\\n\".join([doc.page_content for doc in relevant_pieces[:3]])\n",
    "    \n",
    "    # Ask LLM\n",
    "    FAST_LLM = ChatOpenAI(\n",
    "        model=os.getenv(\"FAST_LLM_MODEL_NAME\"),\n",
    "        api_key=os.getenv(\"FAST_LLM_API_KEY\"),\n",
    "        base_url=os.getenv(\"FAST_LLM_API_BASE\"),\n",
    "    )\n",
    "    # Prepare prompt\n",
    "    completeJobRagPrompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", jobRagPrompt),\n",
    "        (\"human\", \"Extract the job details from this text:\\n\\n{text}\")\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    chain = completeJobRagPrompt | FAST_LLM # \"Why is this a chain?\" no idea :)\n",
    "    \n",
    "    try:\n",
    "        response = chain.invoke({\"text\": combined_context})\n",
    "        # try parsing the response as json\n",
    "        if hasattr(response, 'content'):\n",
    "            json_text = response.content\n",
    "        else:\n",
    "            json_text = str(response)\n",
    "            \n",
    "        json_text = json_text.strip()\n",
    "        \n",
    "        # in case it wraps it in a code block (Not a good way but if it works...)\n",
    "        if json_text.startswith('```json'):\n",
    "            json_text = json_text[7:]\n",
    "        if json_text.endswith('```'):\n",
    "            json_text = json_text[:-3]\n",
    "        json_text = json_text.strip()\n",
    "        \n",
    "        jobPostingText = json.loads(json_text)\n",
    "        print(\"\\n--- Extraction Complete ---\")   \n",
    "        return jobPostingText\n",
    "        \n",
    "    except Exception as error:\n",
    "        print(\"Error: \", error)\n",
    "\n",
    "def extract_job_posting_from_url(jobPostingUrl):\n",
    "    jobPostingHTML = fetchUrl(jobPostingUrl)\n",
    "    jobExtractedText = cleanHTML(jobPostingHTML)\n",
    "    jobPostingText = doRAG(jobExtractedText)\n",
    "    return jobPostingText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d196c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en\"><head>\n",
      "        <meta name=\"pageKey\" content=\"d_jobs_guest_details\">\n",
      "          \n",
      "    <meta name=\"robots\" content=\"max-image-preview:large, noarchive\">\n",
      "      <meta name=\"bingbot\" content=\"max-image-preview:large\">\n",
      "  \n",
      "<!----><!---->        <meta name=\"locale\" content=\"en_US\">\n",
      "<!---->        <meta id=\"config\" data-app-version=\"2.0.2576\" data-call-tree-id=\"AAY/pCTWOh9fZm0uvlrHyA==\" data-multiproduct-name=\"jobs-guest-frontend\" data-service-name=\"jobs-guest-frontend\" data-\n"
     ]
    }
   ],
   "source": [
    "jobPostingHTML = await fetchUrl(jobPostingUrl)\n",
    "print(jobPostingHTML[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "120a4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything To Gain hiring Fully Remote Software Engineer - Cairo in Cairo, Cairo, Egypt | LinkedIn\n",
      "Skip to main content\n",
      "LinkedIn\n",
      "Fully Remote Software Engineer - Cairo in El Qantara Gharb\n",
      "Expand search\n",
      "Jobs\n",
      "This button displays the currently selected search type. When expanded it provides a list of search options that will switch the search inputs to match the current selection.\n",
      "Jobs\n",
      "People\n",
      "Learning\n",
      "Clear text\n",
      "Clear text\n",
      "Clear text\n",
      "Clear text\n",
      "Clear text\n",
      "Join now\n",
      "Sign in\n",
      "Fully Remote Software Eng\n"
     ]
    }
   ],
   "source": [
    "jobExtractedText = cleanHTML(jobPostingHTML)\n",
    "print(jobExtractedText[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7477a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6 chunks.\n",
      "Creating vector store with OpenAI embeddings...\n",
      "Vector store ready.\n",
      "\n",
      "--- Extraction Complete ---\n",
      "{\n",
      "  \"role_summary\": \"Fully remote Software Engineer based in Cairo, responsible for end\\u2011to\\u2011end development of efficient, secure, and user\\u2011friendly software applications.\",\n",
      "  \"key_responsibilities\": [\n",
      "    \"Design, implement, and maintain software applications that fulfill business needs\",\n",
      "    \"Collaborate with product and design teams to define software requirements and technical specifications\",\n",
      "    \"Troubleshoot and optimize existing applications for performance and scalability\",\n",
      "    \"Engage in code reviews and share knowledge with team members to maintain high coding standards\",\n",
      "    \"Research and integrate new technologies to enhance the development process\"\n",
      "  ],\n",
      "  \"required_qualifications\": [\n",
      "    \"Proficiency in programming languages like Python and JavaScript\",\n",
      "    \"Experience with web application development and familiarity with popular front\\u2011end frameworks\",\n",
      "    \"Hands\\u2011on experience with version control systems, particularly Git\",\n",
      "    \"Understanding of Agile development practices\",\n",
      "    \"Strong problem\\u2011solving abilities and attention to detail\",\n",
      "    \"Excellent written and verbal communication skills\"\n",
      "  ],\n",
      "  \"preferred_qualifications\": [\n",
      "    \"Knowledge of database systems (e.g., MySQL, MongoDB) is advantageous\",\n",
      "    \"Experience with RESTful APIs and microservices architecture is a plus\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "jobPostingText = doRAG(jobExtractedText)\n",
    "print(json.dumps(jobPostingText, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ea2a937",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Incoming markup is of an invalid type: <coroutine object fetchUrl at 0x0000029F0A5E6A40>. Markup must be a string, a bytestring, or an open filehandle.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# check if job posting is a url or direct text:\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m jobPostingUrl:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     jobPostingText = \u001b[43mextract_job_posting_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobPostingUrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(json.dumps(jobPostingText, indent=\u001b[32m2\u001b[39m))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mextract_job_posting_from_url\u001b[39m\u001b[34m(jobPostingUrl)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_job_posting_from_url\u001b[39m(jobPostingUrl):\n\u001b[32m    124\u001b[39m     jobPostingHTML = fetchUrl(jobPostingUrl)\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     jobExtractedText = \u001b[43mcleanHTML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobPostingHTML\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     jobPostingText = doRAG(jobExtractedText)\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jobPostingText\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mcleanHTML\u001b[39m\u001b[34m(jobPostingHTML)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcleanHTML\u001b[39m(jobPostingHTML):\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     soup = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobPostingHTML\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml.parser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Remove script and style tags\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m soup([\u001b[33m\"\u001b[39m\u001b[33mscript\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mm:\\Others\\Knitty\\.venv\\Lib\\site-packages\\bs4\\__init__.py:445\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m     markup = cast(io.IOBase, markup).read()\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[33m\"\u001b[39m\u001b[33m__len__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    446\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncoming markup is of an invalid type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmarkup\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Markup must be a string, a bytestring, or an open filehandle.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    447\u001b[39m     )\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) <= \u001b[32m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    449\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m    450\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m   (...)\u001b[39m\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._markup_is_url(markup):\n",
      "\u001b[31mTypeError\u001b[39m: Incoming markup is of an invalid type: <coroutine object fetchUrl at 0x0000029F0A5E6A40>. Markup must be a string, a bytestring, or an open filehandle."
     ]
    }
   ],
   "source": [
    "# check if job posting is a url or direct text:\n",
    "\n",
    "if jobPostingUrl:\n",
    "    jobPostingText = extract_job_posting_from_url(jobPostingUrl)\n",
    "    print(json.dumps(jobPostingText, indent=2))\n",
    "else:\n",
    "    with open(jobPostingPath, 'r', encoding='utf-8') as file:\n",
    "        jobPostingText = file.read().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd189b7",
   "metadata": {},
   "source": [
    "## Make Some AI Calls ü§ô"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a78e60c",
   "metadata": {},
   "source": [
    "First, prepare prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495033ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format cv keyword extraction prompt\n",
    "cvKeywordsPrompt = cvKeywordsPrompt.format(cvText=cvText)\n",
    "# format job posting keyword extraction prompt\n",
    "jobKeywordsPrompt = jobKeywordsPrompt.format(jobPostingText=jobPostingText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvKeywordsPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07920f",
   "metadata": {},
   "source": [
    "012 üòÜ\n",
    "\n",
    "...I mean, hit the api endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_LLM = ChatOpenAI(model=os.getenv(\"FAST_LLM_MODEL_NAME\"),\n",
    "                      base_url=os.getenv(\"FAST_LLM_API_BASE\"),\n",
    "                      api_key=os.getenv(\"FAST_LLM_API_KEY\"),\n",
    "                      )\n",
    "\n",
    "cvKeywordsMessages = [(\n",
    "    \"human\",\n",
    "    cvKeywordsPrompt,\n",
    ")]\n",
    "\n",
    "jobKeywordsMessages = [(\n",
    "    \"human\",\n",
    "    jobKeywordsPrompt,\n",
    ")]\n",
    "\n",
    "cvKeywords = FAST_LLM.invoke(cvKeywordsMessages)\n",
    "print(cvKeywords.content)\n",
    "jobKeywords = FAST_LLM.invoke(jobKeywordsMessages)\n",
    "print(jobKeywords.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c095e",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "Now we need to know how 'similar' the resume is to the job posting.\n",
    "\n",
    "To do this we make two embeddings:\n",
    "\n",
    "1.  An embedding for the entire content of the resume.\n",
    "2.  An embedding for the string of extracted job keywords.\n",
    "\n",
    "An embedding is just a multi-dimensional vector representing the 'meaning' of a token in relation to other tokens.\n",
    "\n",
    "So, by knowing the angle between those two vectors, we can know how 'similar' they are in 'meaning'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdece09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4754827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make the same AI call 3 times and print results separated by a line\n",
    "# responses = []\n",
    "# for _ in range(3):\n",
    "#     resp = FAST_LLM.invoke(cvKeywordsMessages)\n",
    "#     responses.append(resp.content.strip())\n",
    "\n",
    "# print(\"\\n------\\n\".join(responses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knitty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
